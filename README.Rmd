---
title: ""
author: "Jong-Hoon Kim"
date: "1/23/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r, setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE, comment = '', fig.width = 6, fig.height = 6)
extrafont::loadfonts(device = "win", quiet = TRUE)# load fonts - every session
ggplot2::theme_set(theme(text = element_text(family = "Calibri", size = 12),
                         plot.title = element_text(size = 16, hjust = 0, vjust = 0.5),
                         plot.subtitle = element_text(size = 13),
                         plot.caption = element_text(size = 12)))
```


## Parameter (theta) set up
```{r data}
theta_ <- data.table::fread("inst/extdata/theta.csv")
theta <- theta_$val
names(theta) <- theta_$name
y0_ <- data.table::fread("inst/extdata/y0.csv")
y0 <- y0_$val
names(y0) <- y0_[["name"]]
usethis::use_data(y0, overwrite = T)

dat <- readRDS("outputs/kdcadat_pf_10Jan2022.rds")
# > min(which(dat$Delta$daily_confirmed > 0))
# [1] 455
# > min(which(dat$Omicron$daily_confirmed > 0))
# [1] 672

theta[["Delta_start"]] <- 454 #
theta[["Delta_start_date"]] <- as.Date("2021-04-28")
theta[["Omicron_start"]] <- 671  
theta[["Omicron_start_date"]] <- as.Date("2021-12-01")
theta$dt <- 0.2 

usethis::use_data(theta, overwrite = T)
 
devtools::document()
devtools::load_all(".")
```

# Check functions
## process_model
```{r}
np <- 100 # number of particles
tend <- 20
beta = theta[["R0"]] * theta[["gamma"]]
# volatility for beta (random walk)
beta_vol <- matrix(rnorm(np * tend, mean = 0, sd = theta[["betavol"]]), nrow = tend)
beta_vol[1,] <- exp(beta_vol[1,]) * beta # initial beta
y <- data.frame(matrix(0, nrow = np, ncol = length(y0)))
names(y) <- names(y0)
y[,"S"] <- 1e7
y[,"I"] <- 100
yt <- y1 <- process_model(params = theta, y = y, beta = beta_vol[1,])
for (i in 1:100) {
  yt <- process_model(params = theta, y = yt, beta = beta_vol[1,])
}
head(y1)
head(yt)
head(beta_vol[1,])
```

## Rt data generation
```{r}
nt <- 200 # days
param <- list()
param$sigma <- 1/5.2 # 1 / sigma = mean incubation period
param$epsilon <- 1/3 # 1/epsilon = mean latent period
param$gamma <- 1/4.3
param$R <- c(rep(1.2, nt/4), rep(1.4, nt/4), rep(0.8, nt/4), rep(1.2, nt/4))
param$presymp_infect <- FALSE
times <- 0:(nt-1) # simulation times
yini <- c(S = 1e7, E = 40, P = 40, I = 100, R = 0, CE = 0,  CI = 0, CR = 0) # initial values

library(deSolve) 
library(tidyverse)

ode(func = sepir, y = yini, times = times, parms = param) %>%
  as.data.frame() -> out

inf_daily <- diff(out$CE)
onset_daily <- diff(out$CI)
confirm_daily <- diff(out$CR)

df <- data.frame(t = 1:length(param$R), 
                 daily_R_true = param$R, 
                 daily_infect = c(0, inf_daily),
                 daily_onset = c(0, onset_daily),
                 daily_confirm = c(0, confirm_daily))

df %>% 
  pivot_longer(cols = -t) %>%
  filter(name != "daily_R_true") %>% 
  ggplot(aes(t, value, color = name)) +
  geom_line() +
  labs(x = "time (day)", y = "number of individuals", color = "")

# Rt_data <- df
# usethis::use_data(Rt_data, overwrite = T)
```

## particle_filter - sample
```{r}
pf <- particle_filter(data_type = "infection", npart = 1e4, dt = 0.01, error_pdf = "pois")
pf$lik_overall_average
df <- cbind(Rt_data[,1:2], Rt_pf = pf$trace$beta/theta[["gamma"]])
suppressMessages(library(tidyverse))
df %>% pivot_longer(cols = -t) %>% 
  ggplot(aes(t, value, color = name)) + 
  geom_line()
```

## particle_filter - filtered distribution
```{r}
theta[["betavol"]] = 0.4
pf <- particle_filter(data_type = "infection", npart = 1e4, dt = 0.02, error_pdf = "negbin", negbin_size = 100)
pf$lik_overall_average
pr <- c(0.025, 0.25, 0.5, 0.75, 0.975)

Rt_quantile <- as.data.frame(t(apply(pf$beta_filtered/theta[["gamma"]], 1, function(x) {quantile(x, pr)})))
Rt_mean <- data.frame(mean = rowMeans(pf$beta_filtered/theta[["gamma"]]))
df <- cbind(Rt_quantile, Rt_mean, Rt_data[,1:2])

suppressMessages(library(tidyverse))
ggplot(df, aes(x = t)) +
  geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), fill = "grey") +
  geom_line(aes(y = `50%`), size = 1) + 
  geom_line(aes(y = mean), color = "steelblue", size = 1) + 
  geom_point(aes(y = daily_R_true), color = "darkred", size = 1) +
  labs(title = "R(t) via particle filtering", y = "R(t)", x = "Day")

plot_latent_var(sim_res = pf, data_type = "infection")
```

## Particle filtering and backward sampling
$$X(t_k) | Y(t_1)=y^*_1, \dots,\; Y(t_n)=y^*_n,\; X_k | Y_1=y_1^*, \dots,\; Y_n=y_n^*$$

## repeat particle_filter and do backward sampling 
```{r}
res <- run_model(data_type = "infection", rep = 1e2, npart = 1e3, dt = 0.1,
                 systematic_resampling = F)
          
pr <- c(0.025, 0.25, 0.5, 0.75, 0.975)
Rt_quantile <- as.data.frame(t(apply(res$Rt, 1, function(x) {quantile(x, pr)})))
library(data.table)
Rt_mean <- data.frame(mean = rowMeans(res$Rt), 
                      rollmean = frollmean(Rt_quantile[,3], n=7))
df <- cbind(Rt_quantile, Rt_mean, Rt_data[,1:2])
suppressPackageStartupMessages(library(tidyverse))
ggplot(df, aes(x = t)) +
  geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), fill = "grey") +
  geom_line(aes(y = `50%`), size = 1) + 
  geom_line(aes(y = mean), color = "steelblue", size = 1) + 
  geom_point(aes(y = daily_R_true), color = "darkred") +
  labs(title = "R(t) via particle filtering with backward sampling", y = "R(t)", x = "Day")
```

## Parallel forward particle filtering and backward sampling 
```{r}
library(parallel)
library(doParallel)
library(foreach)
ncores = detectCores()
cl <- makeCluster(getOption("cl.cores", ncores-2))
doParallel::registerDoParallel(cl)

system.time({
r <- foreach (i = 1:1e3, .combine = cbind, .packages ="pfilter", .inorder = F) %dopar% {
  run_model(data_type = "infection", rep = 1, npart = 1e4, tend = 200, dt = 0.02, systematic_resampling = FALSE)
}})

parallel::stopCluster(cl)

rt = r[9,] # Rt
rtdf = data.frame(matrix(unlist(rt), ncol=length(rt), byrow=F))
pr <- c(0.025, 0.25, 0.5, 0.75, 0.975)
Rt_quantile <- as.data.frame(t(apply(rtdf, 1, function(x) {quantile(x, pr)})))
library(data.table)
Rt_mean <- data.frame(mean = rowMeans(rtdf), 
                      rollmean = frollmean(Rt_quantile[,3], n=7))
df <- cbind(Rt_quantile, Rt_mean, Rt_data[,1:2])
suppressPackageStartupMessages(library(tidyverse))
ggplot(df, aes(x = t)) +
  geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), fill = "grey") +
  geom_line(aes(y = `50%`), size = 1) + 
  geom_line(aes(y = mean), color = "steelblue", size = 1) + 
  geom_point(aes(y = daily_R_true), color = "darkred", size = 1) +
  labs(title = "R(t) via particle filtering with backward sampling", y = "R(t)", x = "Day")

plot_latent_var_pl(sim_res = r, data_type = "infection")
```


## parallel repeat particle_filter and do backward sampling 
```{r}
devtools::load_all(".")
library(parallel)
library(doParallel)
library(foreach)
ncores = detectCores()
cl <- makeCluster(getOption("cl.cores", ncores-2))
doParallel::registerDoParallel(cl)
system.time({
r <- foreach (i=1:1e3, .combine = cbind, .packages = "pfilter", .inorder = F) %dopar% {
  run_model(params = theta, y = y0, data = Rt_data, data_type = "confirmation",
            rep = 1, npart = 1e3, tend = 200, dt = 0.1, 
            systematic_resampling = FALSE)
}})
parallel::stopCluster(cl)

rt <- r[9,] # Rt
rtdf = data.frame(matrix(unlist(rt), ncol=length(rt), byrow=F))
pr <- c(0.025, 0.25, 0.5, 0.75, 0.975)
Rt_quantile <- as.data.frame(t(apply(rtdf, 1, function(x) {quantile(x, pr)})))
library(data.table)
Rt_mean <- data.frame(mean = rowMeans(rtdf), 
                      rollmean = frollmean(Rt_quantile[,3], n=7))
df <- cbind(Rt_quantile, Rt_mean, Rt_data[,1:2])
suppressPackageStartupMessages(library(tidyverse))
ggplot(df, aes(x = t)) +
  geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), fill = "grey") +
  geom_ribbon(aes(ymin = `25%`, ymax = `75%`), fill = "grey50") +
  geom_line(aes(y = `50%`), size = 1) + 
  geom_line(aes(y = mean), color = "steelblue", size = 1) + 
  geom_line(aes(y = daily_R_true), color = "darkred") +
  labs(title = "R(t) via particle filtering with backward sampling", y = "R(t)", x = "Day")

plot_latent_var_pl(sim_res = r, data_type = "confirmation")
```

## Maximum likelihood estimation test
```{r}
# devtools::load_all(".")
mle <- maxlik(data_type = "confirmation")

df <- cbind(Rt_data[,1:2], (mle$beta_trace/theta[name == "gamma", val]))
suppressPackageStartupMessages(library(tidyverse))
df %>% 
  pivot_longer(cols = - t) %>%
  ggplot(aes(t, value, color = name)) +
  geom_line() +
  geom_point() +
  labs(title = "R(t) via maximum likelihood", y = "R(t)", x = "Day")

```

## run_step function 
```{r eval=F}
# nc <- 1
# S <- rep(1e3, nc)
# E <- rep(10, nc)
# P <- rep(10, nc)
# I <- rep(10, nc)
# R <- rep(0, nc)
# daily_infect <- rep(0, nrow(y))
# daily_symptom <- rep(0, nrow(y))
# daily_confirm <- rep(0, nrow(y))
# 
# yini <- data.frame(S = S, E = E, P = P, I = I, R = R, CE = daily_infect, CI = daily_symptom, CR = daily_confirm)
# 
# run_step <- function(y, times, params){
#   param$presymp_infect <- FALSE
#   out <- as.data.frame(ode(y = y, func = sepir, times = times, parms = param))
#   tail(out, 1)
# }
#     
# # yini <- c(S = 1e7, E = 40, P = 40, I = 100, R = 0, CE = 0,  CI = 0, CR = 0) # initial values
# out <- apply(yini, 1, run_step, times = c(0, 1), params = as.list(theta))
# outdf <- data.frame(matrix(unlist(out), nrow = length(out), byrow = T))
# outdf <- outdf[, -1] # remove the time column
# names(outdf) <- names(yini)
```


## KDCA data
### Data cleaning
```{r}
library(readxl)
suppressMessages(library(tidyverse))
d <- read_xlsx("covid_kdca.xlsx")
names(d) = c("id", "nationality", "sex", "age", "sido", "sigungu", "date_symptom_onset", "date_diagnosis", "date_report", "route_infection", "country_orgin", "id_infector", "occupation")
d1 <- d %>% filter(route_infection == "국내")%>% 
  select(date_diagnosis) %>% 
  group_by(date = date_diagnosis) %>% 
  summarise(daily_confirm = n())
d2 <- data.frame(date = seq(as.Date("2020-01-03"), as.Date("2021-02-23"), by = "day"))
d2$t <- 1:nrow(d2)
d3 <- left_join(d2, d1, by = "date")
kdca_dat <- d3 %>% mutate(daily_confirm = ifelse(is.na(daily_confirm), 0, daily_confirm))

# saveRDS(dat, paste0( "outputs/dat_", tstamp, ".rds"))
## name standardization
ggplot(kdca_dat, aes(t, daily_confirm)) +
  geom_line()

# library(data.table)
# dat$daily_confirm <- frollmean(dat$daily_confirm, n = 7)
# dat <- dat[7:nrow(dat),]
# dat$t <- 1:nrow(dat)
# dat$daily_confirm <- round(dat$daily_confirm)
```



### Data fitting - forward filtering
```{r}
dat <- kdca_dat
theta[["betavol"]] = 0.55
ynew <- c(S = 5*1e7, E = 1e1, P = 1e1, I = 1e1, R = 0, CE = 0, CI = 0, CR = 0)
set.seed(10)
pf <- particle_filter(y = ynew, data = dat, data_type = "confirmation", 
                      npart = 2e4, tend = nrow(dat), dt = 0.2, 
                      error_pdf = "negbin", negbin_size = 20)

pf$lik_overall_average
pr <- c(0.025, 0.25, 0.5, 0.75, 0.975)
Rt_quantile <- as.data.frame(t(apply(pf$beta_filtered/theta[["gamma"]], 1, 
                                     function(x) {quantile(x, pr)})))
Rt_mean <- data.frame(mean = rowMeans(pf$beta_filtered/theta[["gamma"]]))
df <- cbind(Rt_quantile, Rt_mean, dat[,c("t", "date")])
df$date <- seq(as.Date("2020-01-20"), length.out = nrow(df), by = "day")
suppressMessages(library(tidyverse))

ggplot(df, aes(x = date)) +
  geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), fill = "grey") +
  geom_ribbon(aes(ymin = `25%`, ymax = `75%`), fill = "grey60") +
  geom_line(aes(y = `50%`), color = "steelblue", size = 1, linetype = "dotted") + 
  geom_line(aes(y = mean), color = "steelblue", size = 1) + 
  labs(title = "R(t) via particle filtering", y = "R(t)", x = "") +
  geom_hline(yintercept = 1, color = "black", linetype = "dotted") + 
  scale_y_continuous(limits = c(0, 10), breaks = c(0, 1, seq(2, 10, 2)), 
                     labels = c(0, 1, seq(2, 10, 2))) + 
  scale_x_date(date_breaks = "2 month", date_minor_breaks = "1 month", 
               limits = c(as.Date("2020-01-20"), max(df$date)))

plot_latent_var(sim_res = pf, data = dat, data_type = "confirmation")
```

### Parallel - forward filtering with backward sampling
```{r}
y0 <- c(S = 5*1e7, E = 1e1, P = 1e1, I = 1e1, R = 0, CE = 0, CI = 0, CR = 0)
theta["betavol"] <- 0.6
usethis::use_data(y0, overwrite = T)
usethis::use_data(theta, overwrite = T)
devtools::load_all(".")

library(parallel)
library(doParallel)
library(foreach)
ncores = detectCores()
cl <- makeCluster(getOption("cl.cores", ncores-2))
doParallel::registerDoParallel(cl)

system.time({
r <- foreach (i = 1:1e3, .combine = cbind, .packages ="pfilter", .inorder = F) %dopar% {
  run_model(params = theta, y = y0, data = dat, data_type = "confirmation",
            rep = 1, npart = 1e4, tend = nrow(dat), dt = 0.1, error_pdf = "negbin", negbin_size = 10,
            systematic_resampling = FALSE)
}})
parallel::stopCluster(cl)

# tstamp <- format(Sys.time(), "%Y%m%dT%H%M%S")
# saveRDS(r, paste0( "outputs/ffbs_", tstamp, ".rds"))
tstamp <- "20210305T141259"
r <- readRDS(paste0( "outputs/ffbs_", tstamp, ".rds"))
dat <- readRDS(paste0( "outputs/dat_", tstamp, ".rds"))


rt <- r[9,] # Rt
rtdf = data.frame(matrix(unlist(rt), ncol=length(rt), byrow=F))
pr <- c(0.025, 0.25, 0.5, 0.75, 0.975)
Rt_quantile <- as.data.frame(t(apply(rtdf, 1, function(x) {quantile(x, pr)})))
library(data.table)
Rt_mean <- data.frame(mean = rowMeans(rtdf), 
                      rollmean = frollmean(Rt_quantile[,3], n=7))
df <- cbind(Rt_quantile, Rt_mean, dat[, 2:3])
df$date <- seq(as.Date("2020-01-20"), length.out = nrow(df), by = "day")
suppressMessages(library(tidyverse))

ggplot(df, aes(x = date)) +
  geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), fill = "steelblue", alpha = 0.3) +
  geom_ribbon(aes(ymin = `25%`, ymax = `75%`), fill = "steelblue", alpha = 0.6) +
  geom_line(aes(y = `50%`), color = "steelblue", size = 1, linetype = "dotted") + 
  geom_line(aes(y = mean), color = "steelblue", size = 1) + 
  labs(title = "R(t) via particle filtering with backward sampling", y = "R(t)", x = "Day") +
  geom_hline(yintercept = 1, color = "darkred", size = 1, linetype = "dotted") +
  scale_y_continuous(limits = c(0, 10), breaks = c(0, 1, seq(2, 10, 2)), labels = c(0, 1, seq(2, 10, 2))) + 
  scale_x_date(date_breaks = "2 month", date_minor_breaks = "1 month", limits = c(as.Date("2020-01-20"), max(df$date))) +
  labs(x = "", y = "R(t)") 
  # theme(axis.text.x = element_text(angle = 0, vjust = 1.0, hjust = 0.5))
# ggsave("plots/Rt_ffbs.png", width = 16, height = 9, scale = 1, units = "cm")
# plt <- plot_latent_var_pl(sim_res = r, data = dat, data_type = "confirmation")
# ggsave("plots/daily_confirm_ffbs.png", plt, width = 16, height = 9, scale = 1, units = "cm")
```

## Can we stop and continue at any arbitrary time step?
That is, can we fun the PF 
1. particle_filter function that takes the weight (W) and particle ID (A) matrix, 
beta, and latent variable

```{r}
theta[["betavol"]] = 0.5
ynew <- c(S = 5*1e7, E = 1e1, P = 1e1, I = 1e1, R = 0, CE = 0, CI = 0, CR = 0)
set.seed(10)
tbegin <- 100
tend <- 100
dat <- kdca_dat[tbegin:(tend+tbegin-1),]
y_pf <- as.data.frame(pf$latent_var_filtered[,tend,])
names(y_pf) <- names(y0)
beta_pf <- pf$beta_filtered[tend,]

pf <- particle_filter(y = y_pf, beta0 = beta_pf,
                      data = dat, data_type = "confirmation", 
                      npart = 2e4, tend = tend, dt = 0.1,
                      error_pdf = "negbin", negbin_size = 15)
 
pf$lik_overall_average
pr <- c(0.025, 0.25, 0.5, 0.75, 0.975)
Rt_quantile <- as.data.frame(t(apply(pf$beta_filtered/theta[["gamma"]], 1, 
                                     function(x) {quantile(x, pr)})))
Rt_mean <- data.frame(mean = rowMeans(pf$beta_filtered/theta[["gamma"]]))
df <- cbind(Rt_quantile, Rt_mean, dat[,c("t", "date")])
# df$date <- seq(as.Date("2020-01-03") + tbegin - 1, length.out = nrow(df), by = "day")

suppressMessages(library(tidyverse))

ggplot(df, aes(x = date)) +
  geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), fill = "steelblue", alpha = 0.3) +
  geom_ribbon(aes(ymin = `25%`, ymax = `75%`), fill = "steelblue", alpha = 0.6) +
  geom_line(aes(y = `50%`), color = "steelblue", size = 1, linetype = "dotted") + 
  geom_line(aes(y = mean), color = "steelblue", size = 1) + 
  labs(title = "R(t) via particle filtering", y = "R(t)", x = "") +
  geom_hline(yintercept = 1, color = "red", linetype = "dotted") + 
  # scale_y_continuous(limits = c(0, 10), breaks = c(0, 1, seq(2, 10, 2)), 
  #                    labels = c(0, 1, seq(2, 10, 2))) + 
  scale_x_date(date_breaks = "2 month", date_minor_breaks = "1 month", 
               limits = c(min(df$date), max(df$date)))

plot_latent_var(sim_res = pf, data = dat, data_type = "confirmation")

```

## Testing arma::cube can be access through _ just like in Rcpp::NumericMatrix
```{r}
library(Rcpp)
library(RcppArmadillo)
sourceCpp("cpp/test.cpp")
# a = array(1:12, c(2,3,2))
# a[, , 1]
# (a = export_array(Q = a, slice = 0))
# # (m = export_mat(Q = a, slice = 0))
# (v = export_vec(Q = a, col = 0, slice = 0))
# (i = to_int(x = c(1.0, 2.2)))
# m = matrix(1:12, nrow = 3)
# m[,1]
# (v = export_vec_from_mat(m = m, col = 0))
# (ch = add_x("mr. "))
# all_x("x")
# all_x("y")
int_sample(10)
int_wt_sample(10, wt = c(0.8,0.2,rep(0,8)))
sample_test(10, wt = c(0.8,0.2,rep(0,8)))
```

## testing assign_weights function
```{r}
library(Rcpp)
library(RcppArmadillo)
sourceCpp("cpp/assign_weights_cpp.cpp")
st_now = data.matrix(data.frame(S=rep(1,10), E1 = rep(1,10), E2 = rep(1,10), I = rep(1,10), R = 1:10, CE1 = 101:110, CI = 101:110))
st_before = data.matrix(data.frame(S=rep(1,10), E1 = rep(1,10), E2=rep(1,10), I = rep(1,10), R = 1:10-1, CE1 = round(seq(1, 100, length.out = 10)), CI = round(seq(1, 100, length.out = 10))))

wt = assign_weights_cpp(st_now, st_before, 53L, data.matrix(Rt_data), "infection")
all.equal(wt[1], dpois(101,100))
```

## testing particle_filter_cpp function
```{r}
library(Rcpp)
library(RcppArmadillo)
sourceCpp("cpp/particle_filter_cpp.cpp")
```

##Conditional log likelihood
The estimated conditional log likelihood from a fitted model.
The conditional likelihood is defined to be the value of the density
\[ Y(t_k) | Y(t_1),\dots,Y(t_{k-1}) Y_k | Y_1,\dots,Y_{k-1}\] 
evaluated at \[Y(t_k) = y^*_k Y_k = y_k^*\].

Here, \({Y(t_k)}{Yk}\) is the observable process, and \(y^*_kyk*}\) the data, at time \(t_k\).

Thus the conditional log likelihood at time \(t_k\) is
\[{\ell_k(\theta) = \log f[Y(t_k)=y^*_k \vert Y(t_1)=y^*_1, \dots, Y(t_{k-1})=y^*_{k-1}],}{ell_k(theta)=log f[Yk = yk* | Y1=y1*, \dots, Y(k-1)=y(k-1)*],}\]
where is the probability density above.


## KDCA data
```{r}
library(readxl)
Sys.setlocale("LC_ALL", "Korean")
dat <- read_xlsx('data/kdca.xlsx')
dat$date_reported <- as.Date(dat$보도일, format = "%Y-%m-%d")
dat$date_symptom <- as.Date(dat$발병일, format = "%Y-%m-%d")
dat$date_diagnosed <- as.Date(dat$진단일, format = "%Y-%m-%d")
dat$date_notified <- as.Date(dat$신고일, format = "%Y-%m-%d")

## Fix typing mistakes for the years
valid_year <- function(data, yrs = c(2020, 2021)) {
  tf <- format(data$date_diagnosed, "%Y") %in% yrs
  tf <- rbind(tf, format(data$date_symptom, "%Y") %in% yrs)
  tf <- rbind(tf, format(data$date_reported, "%Y") %in% yrs)
  tf <- rbind(tf, format(data$date_notified, "%Y") %in% yrs)
  validyr <- apply(tf, 2, all)
  return(data[validyr, ])
}
dat_ <- dat
dat <- valid_year(dat)

library(dplyr)
dat$delay_onset_diagnosis <- dat$date_diagnosed - dat$date_symptom

library(ggplot2)
dat %>% 
  group_by(date_symptom) %>% 
  summarize(n = n(),
            s = sum(delay_onset_diagnosis),
            avg = s/n) %>% 
  ggplot(aes(x = date_symptom)) +
  geom_line(aes(y = as.numeric(avg))) + 
  scale_y_continuous(limits = c(0,10)) +
  labs(y = "Daily mean delay from onset to diagnosis", 
       x = "Date of symptom onset")

# serial interval
dat$infector_id <- as.integer(dat$선행확진자_id)

create_sidata <- function(dat){
  sidat <- data.frame(matrix(NA, nrow = nrow(dat), ncol = 5))
  names(sidat) <- c("infectee_id", "infectee_symptom_onset_date", "infector_id", "infector_symptom_onset_date", "serial_interval")
  x <- 1
  for (i in 1:nrow(dat)){
    infector_id <- dat$infector_id[i]
    if (!is.na(infector_id)){
      # cat("i = ", i, ", infector_id = ", infector_id, "\n")
      sidat$infectee_id[x] <- dat$id[i]
      sidat$infectee_symptom_onset_date[x] <- 
        format(dat$date_symptom[i], "%Y-%m-%d")
      sidat$infector_id[x] <- infector_id
      loc <- match(infector_id, dat$id)
      # cat("infector location = ", infector_loc, "\n")
      if (length(loc) == 1) {
        infector_symptom_date <- format(dat$date_symptom[loc], "%Y-%m-%d")
        # cat("infector symptom date = ", infector_symptom_date, "\n")
        sidat$infector_symptom_onset_date[x] <- infector_symptom_date
        x <- x + 1
      } else if (length(loc) > 1) {
        cat("Infector id matched multiple times!\n")
      } else{
        cat("Infector id not identified!\n")
      }
    }
  }
  sidat$infectee_symptom_onset_date <- 
    as.Date(sidat$infectee_symptom_onset_date)
  sidat$infector_symptom_onset_date <- 
    as.Date(sidat$infector_symptom_onset_date) 
  sidat$serial_interval <- 
    as.numeric(sidat$infectee_symptom_onset_date - infector_symptom_onset_date)
  return(sidat)
}

sidat <- create_sidata(dat)

library(magrittr)
sidat %<>% 
  mutate(
    infectee_symptom_onset_date  = as.Date(infectee_symptom_onset_date), 
    infector_symptom_onset_date  = as.Date(infector_symptom_onset_date),
    serial_interval = as.numeric(infectee_symptom_onset_date - infector_symptom_onset_date))

sidat %>%
  filter(!is.na(infector_symptom_onset_date)) %>% 
  ggplot(aes(x = infector_symptom_onset_date)) +
  geom_point(aes(y = serial_interval))

sidat %>% 
  group_by(infector_symptom_onset_date) %>% 
  summarise(n = n(),
            mean = mean(serial_interval, na.rm = T),
            median = median(serial_interval, na.rm = T), 
            q1 = quantile(serial_interval, probs = 0.25, na.rm = T),
            q3 = quantile(serial_interval, probs = 0.75, na.rm = T),
            IQR = q3 - q1,
            lower_fence = q1 - 1.5*IQR, 
            upper_fence = q3 + 1.5*IQR) -> sidat_summary

sidat_summary %>% 
  filter(!is.na(infector_symptom_onset_date)) %>%
  ggplot(aes(x = infector_symptom_onset_date)) +
  geom_line(aes(y = median), color = "darkred") +
  geom_point(aes(y = median), color = "darkred") +
  geom_segment(aes(x = infector_symptom_onset_date, xend = infector_symptom_onset_date,
              y = upper_fence, yend = lower_fence), size = 0.6) +
  scale_y_continuous(limits = c(-20,20)) + 
  labs(x = "Date of infector symptom onset", 
       y = "Daily serial interval")

dat %>% 
  group_by(date_reported) %>% 
  summarize(n = n()) %>% 
  ggplot(aes(date_reported, n)) + 
  geom_line()
## quite a few individuals developed symptoms and were diagnosed on the same day
# length(as.numeric(dat$delay_onset_diagnosis[dat$delay_onset_diagnosis<50 & dat$delay_onset_diagnosis==0]))
# [1] 37697

# weekly average of serial interval

```

### Gyeonggi-do data
```{r}
library(dplyr)
dat %>% 
  filter(감염경로 == "국내", 거주시도 == "경기") %>% 
  group_by(date_reported) %>% 
  summarize(daily_confirmed = n()) -> gg
names(gg) <- c("date", "daily_confirmed")

## To fill up the dates on the gg dataset such data each data point is equidistant
dat1 <- data.frame(date = gg$date, daily_confirmed = gg$daily_confirmed)
dat2 <- data.frame(date = seq(min(gg$date), max(gg$date), by = "day"), 
                  daily_confirmed = 0)

# dat2[nrow(dat2)-1, 2] <- 363
# dat2[nrow(dat2), 2] <- 403
dat <- left_join(dat2, dat1, by = "date")
dat_ <- dat
dat <- dat[, c("date", "daily_confirmed.y")]
names(dat) <- c("date", "daily_confirmed")
dat$daily_confirmed[is.na(dat$daily_confirmed)] <- 0

## read from manually compiled data (provided by Sun-hwa Choi)
library(readxl)
dat <- read_xlsx("data/korea_confirmed_region_sun.xlsx")
dat <- dat[, c(1, 10)] #Gyeonggi-do
names(dat) <- c("date", "daily_confirmed")
dat$date <- as.Date(dat$date, "%Y-%m-%d")
dat$daily_confirmed[is.na(dat$daily_confirmed)] <- 0
dat <- dat[!is.na(dat$date), ] 
library(pfilter)
# devtools::load_all(".")
library(parallel)
library(doParallel)
library(foreach)
# latent variables for 1 Jan 2021 estimated by  previous particle filtering
# simulations that used data from 20 Jan 2020
# dat_ <- dat
## fit first of the 
dat <- dat[dat$date < as.Date("2021-01-10"), ]
theta["betavol"] <- 0.08
theta["gamma"] <- 1/2.5
usethis::use_data(theta, overwrite = T)
devtools::load_all(".")
gg_pop <- 13740000
y0 <- c(S = gg_pop - 10, E = 0, P = 0, I = 10, R = 0, CE = 0, CI = 0, 
        CR = 0, A = 0)
set.seed(23)

ncores <- detectCores()
cl <- makeCluster(getOption("cl.cores", ncores - 2))
doParallel::registerDoParallel(cl)

pf <- foreach(i = 1:1e3, .packages = "pfilter", .inorder = F) %dopar% {
  extract_trace(params = theta,
                y = y0,
                data = dat,
                data_type = "confirmation",
                npart = 1e4,
                tend = nrow(dat),
                dt = 0.25,
                error_pdf = "negbin",
                negbin_size = 15,
                stoch = TRUE)
}
parallel::stopCluster(cl)

saveRDS(pf, "outputs/pf_gg.rds")
Rt <- as.data.frame(sapply(pf, function(x) x[, "Rt"]))
daily_conf <- as.data.frame(sapply(pf, function(x) x[, "CR"]))
## save as the csv files as they are easier to
write.csv(Rt, "outputs/Rt_gg.csv", row.names = FALSE)
write.csv(daily_conf, "outputs/daily_confirmed_gg.csv", row.names = FALSE)

vars <- c("S", "E", "P", "I", "R", "CE", "CI", "CR", "A") 

y20210101_gg <- data.frame(matrix(NA, nrow = 1000, ncol = length(vars)))
names(y20210101_gg) <- vars
for (i in 1:length(vars)){
  df <- as.data.frame(sapply(pf, function(x) x[, vars[i]]))
  y20210101_gg[1:1000, i] <- as.numeric(df[318, 1:1000])
}
# saveRDS(y20210101_gg, "outputs/y20210101_gg.rds")


# pr <- c(0.025, 0.25, 0.5, 0.75, 0.975)
# df <- as.data.frame(sapply(pf, function(x) x[, "Rt"]))
# Rt_quantile <- as.data.frame(t(apply(df, 1, function(x) quantile(x, pr))))
# df <- cbind(Rt_quantile, dat[, c("date", "daily_confirmed")])
# library(ggplot2)
# ggplot(df, aes(x = date)) +
#   geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), fill = "steelblue", alpha = 0.4) +
#   geom_ribbon(aes(ymin = `25%`, ymax = `75%`), fill = "steelblue", alpha = 0.6) +
#   geom_line(aes(y = `50%`), color = "steelblue", size = 1) +
#   labs(title = expression(R[t]~estimated~using~particle~filtering),
#        y = expression(R[t]), x = "") +
#   geom_hline(yintercept = 1, color = "darkred", size = 1, linetype = "dotted") +
#   scale_x_date(date_breaks = "2 month", limits = c(min(df$date), max(df$date)))
# 
# # ggsave(paste0("plots/Rt", tstamp, ".png"), plt, width = 8, height = 5, dpi = 600,
# #        scale = 2, units = "cm", type = "cairo")
# # ggsave(paste0("plots/Rt", tstamp, ".pdf"), plt, width = 8, height = 5, dpi = 600,
# #        scale = 1, units = "cm", device = cairo_pdf)
# 
# daily_conf <- as.data.frame(sapply(pf, function(x) x[, "CR"]))
# daily_conf_quantile <- as.data.frame(t(apply(daily_conf, 1, function(x) quantile(x, pr))))
# df <- cbind(daily_conf_quantile, dat[, c("date", "daily_confirmed")])
# 
# ggplot(df, aes(x = date)) +
#   geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`),
#               fill = "steelblue", alpha = 0.4) +
#   geom_ribbon(aes(ymin = `25%`, ymax = `75%`),
#               fill = "steelblue", alpha = 0.6) +
#   geom_line(aes(y = `50%`), color = "steelblue", size = 1) +
#   labs(title = "Daily confirmed case estimated using particle filtering",
#        y = "R(t)", x = "Day") +
#   geom_point(aes(y = daily_confirmed), color = "darkred", size = 1) +
#   scale_x_date(date_breaks = "2 month", date_minor_breaks = "1 month") +
#   labs(x = "", y = "Daily confirmed case")
# 

## year 
local <- filter(dat, 감염경로 == "국내") 

korea_informed <-  local %>% 
  group_by(신고일) %>% 
  summarize(case = n())
names(korea_informed) <- c("date", "case")

gg_informed <- local %>%
  filter(거주시도 == "경기") %>% 
  group_by(신고일) %>% 
  summarize(case = n())
names(gg_informed) <- c("date", "case")


korea_onset <- dat %>% 
  filter(감염경로 == "국내") %>% 
  group_by(onset_new) %>% 
  summarize(case = n())
names(korea_onset) <- c("date", "case")

gg <- dat %>% 
  filter(거주시도 == "경기") %>% 
  group_by(보도일) %>% 
  summarize(case = n())
names(gg) <- c("date", "case")


gsub("(^\\d{4}).*", "\\1", dat$보도일[62116])
gsub("(^\\d{4}).*", "\\1", dat$보도일[62116])
gsub("^[^\\d{4}]+\\d{2}", "\\1", dat$보도일[62116])
                                    
as.Date(dat$보도일[62116], format = "%m-%d")

```

### Gyeonggi-do data particle filtering 
```{r}
library(dplyr)
library(data.table)
# Kyeonggi data set
# dat0 <- gg_informed
# dat0 <- korea_informed
dat0 <- readRDS("gyeonggi.rds")
names(dat0) <- c("date", "daily_confirmed")
dat1 <- data.frame(date = dat0$date, daily_confirmed = dat0$daily_confirmed)
dat2 <- data.frame(date = seq(min(dat0$date), 
                              max(dat0$date), by = "day"), 
                  daily_confirmed = 0)

# dat2[nrow(dat2)-1, 2] <- 363
# dat2[nrow(dat2), 2] <- 403
dat <- left_join(dat2, dat1, by = "date")
dat_ <- dat
dat <- dat[, c("date", "daily_confirmed.y")]
names(dat) <- c("date", "daily_confirmed")
dat$daily_confirmed[is.na(dat$daily_confirmed)] <- 0

dat$rollmean <- round(frollmean(dat$daily_confirmed, 7, align = "center"))

# dat[nrow(dat)-1, 2] <- 363
# dat[nrow(dat), 2] <- 403

# devtools::install()
library(pfilter)
# devtools::load_all(".")
library(parallel)
library(doParallel)
library(foreach)
# latent variables for 1 Jan 2021 estimated by  previous particle filtering
# simulations that used data from 20 Jan 2020
dat_ <- dat
dat <- dat[dat$date > as.Date("2020-02-06") & dat$date < as.Date("2021-07-18") , c("date", "rollmean")]
names(dat) <- c("date", "daily_confirmed")
theta["betavol"] <- 0.08
theta["gamma"] <- 1/2.2
usethis::use_data(theta, overwrite = T)
devtools::load_all(".")
gg_pop <- 13740000
kr_pop <- 50000030
y0 <- c(S = gg_pop - 10, E = 0, P = 0, I = 10, R = 0, CE = 0, CI = 0, 
        CR = 0, A = 0)
set.seed(23)

ncores <- detectCores()
cl <- makeCluster(getOption("cl.cores", ncores - 2))
doParallel::registerDoParallel(cl)

pf <- foreach(i = 1:1e3, .packages = "pfilter", .inorder = F) %dopar% {
  extract_trace(params = theta,
                y = y0,
                data = dat,
                data_type = "confirmation",
                npart = 1e3,
                tend = nrow(dat),
                dt = 0.2,
                error_pdf = "negbin",
                negbin_size = 15,
                stoch = FALSE)
}
parallel::stopCluster(cl)

pr <- c(0.025, 0.25, 0.5, 0.75, 0.975)
df <- as.data.frame(sapply(pf, function(x) x[, "Rt"]))
Rt_quantile <- as.data.frame(t(apply(df, 1, function(x) quantile(x, pr))))
df <- cbind(Rt_quantile, dat[, c("date", "daily_confirmed")])
library(ggplot2)
ggplot(df, aes(x = date)) +
  geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), fill = "steelblue", alpha = 0.4) +
  geom_ribbon(aes(ymin = `25%`, ymax = `75%`), fill = "steelblue", alpha = 0.6) +
  geom_line(aes(y = `50%`), color = "steelblue", size = 1) + 
  labs(title = expression(R[t]~estimated~using~particle~filtering),
       y = expression(R[t]), x = "") +
  geom_hline(yintercept = 1, color = "darkred", size = 1, linetype = "dotted") +
  scale_x_date(date_breaks = "2 month", limits = c(min(df$date), max(df$date)))

# ggsave(paste0("plots/Rt", tstamp, ".png"), plt, width = 8, height = 5, dpi = 600,
#        scale = 2, units = "cm", type = "cairo")
# ggsave(paste0("plots/Rt", tstamp, ".pdf"), plt, width = 8, height = 5, dpi = 600,
#        scale = 1, units = "cm", device = cairo_pdf)

daily_conf <- as.data.frame(sapply(pf, function(x) x[, "CR"]))
daily_conf_quantile <- as.data.frame(t(apply(daily_conf, 1, function(x) quantile(x, pr))))
df <- cbind(daily_conf_quantile, dat[, c("date", "daily_confirmed")])

ggplot(df, aes(x = date)) +
  geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), 
              fill = "steelblue", alpha = 0.4) +
  geom_ribbon(aes(ymin = `25%`, ymax = `75%`), 
              fill = "steelblue", alpha = 0.6) +
  geom_line(aes(y = `50%`), color = "steelblue", size = 1) + 
  labs(title = "Daily confirmed case estimated using particle filtering", 
       y = "R(t)", x = "Day") +
  geom_point(aes(y = daily_confirmed), color = "darkred", size = 1) +
  scale_x_date(date_breaks = "2 month", date_minor_breaks = "1 month") +
  labs(x = "", y = "Daily confirmed case")

# ggsave(paste0("plots/daily_confirmed", tstamp, ".png"), plt,  width = 3.4, 
#        height = 2.7, scale = 2, units = "in")
# ggsave(paste0("plots/daily_confirmed", tstamp, ".png"), plt, width = 8, height = 5, dpi = 600, scale = 2, units = "cm", type = "cairo")
```

## Fitting renewal equation data using particle filtering 
```{r}
datpf <- data.frame(date = seq(as.Date("2021-01-01"), by = "day", 
                               length.out = nrow(dat)), 
                    daily_infected = dat$I)

library(pfilter)
# devtools::load_all(".")
library(parallel)
library(doParallel)
library(foreach)
nms <- c("date", "daily_infected")
names(datpf) <- nms
theta["betavol"] <- 0.6
theta["gamma"] <- 1/2
theta["delta"] <- 1/4
theta["epsilon"] <- 1/2
usethis::use_data(theta, overwrite = T)
devtools::load_all(".")
pop <- 50000030
y0 <- c(S = pop - 10, E = 0, P = 0, I = 10, R = 0, CE = 0, CI = 0, 
        CR = 0, A = 0)
set.seed(23)

ncores <- detectCores()
cl <- makeCluster(getOption("cl.cores", ncores - 2))
doParallel::registerDoParallel(cl)

pf <- foreach(i = 1:1e3, .packages = "pfilter", .inorder = F) %dopar% {
  extract_trace(params = theta,
                y = y0,
                data = datpf,
                data_type = "infection",
                npart = 1e4,
                tend = nrow(datpf),
                dt = 0.2,
                error_pdf = "pois",
                negbin_size = 15,
                stoch = FALSE)
}
parallel::stopCluster(cl)

pr <- c(0.025, 0.25, 0.5, 0.75, 0.975)
df <- as.data.frame(sapply(pf, function(x) x[, "Rt"]))
Rt_quantile <- as.data.frame(t(apply(df, 1, function(x) quantile(x, pr))))
df <- cbind(Rt_quantile, datpf[, nms])
library(ggplot2)
ggplot(df, aes(x = date)) +
  geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), fill = "steelblue", alpha = 0.4) +
  geom_ribbon(aes(ymin = `25%`, ymax = `75%`), fill = "steelblue", alpha = 0.6) +
  geom_line(aes(y = `50%`), color = "steelblue", size = 1) + 
  labs(title = expression(R[t]~estimated~using~particle~filtering),
       y = expression(R[t]), x = "") +
  geom_hline(yintercept = c(1.2, 1, 2.2, 0.8), color = "darkred", size = 1, linetype = "dotted") +
  scale_x_date(date_breaks = "2 month", limits = c(min(df$date), max(df$date)))

plot(1:length(Rt), Rt, col = 2)
lines(df$`50%`, type = "l")
```

## Data extraction from API (by region)
```{r}
library(XML)
library(RCurl)
library(dplyr)
# Sys.setlocale("LC_ALL", "Korean")
# options(encoding = "UTF-8")
## data portal
service_url <- "http://openapi.data.go.kr/openapi/service/rest/Covid19/getCovid19SidoInfStateJson"
rows <- 4 #number of rows
## page
pg <- 1
# service key (register at https://www.data.go.kr/data/15043376/openapi.do)
# web site also provides a api request tool to check if the service key works
# decoded key works for the web site but in R encoded key (with the percent sign works)
# service_key <- "KNu/yp3/Km2MWttRvbZXNE+b/EH44cfIYDvMgPFoSKUuKZIxqQoGu0gnAtwslGjupx+E6vp0bwf/SRPcLfXSYQ=="
service_key <- "KNu%2Fyp3%2FKm2MWttRvbZXNE%2Bb%2FEH44cfIYDvMgPFoSKUuKZIxqQoGu0gnAtwslGjupx%2BE6vp0bwf%2FSRPcLfXSYQ%3D%3D"
## service period
start_dt <- gsub("-", "", as.character(Sys.Date()))
end_dt <- start_dt

start_dt <- "20200401"
end_dt <- "20210723"

uri <-  paste0(service_url,
               paste0("?serviceKey=", service_key),
               paste0("&pageNo=", pg),
               paste0("&numOfRows=", rows),
               paste0("&startCreateDt=", start_dt),
               paste0("&endCreateDt=", end_dt))

xml_doc <- xmlTreeParse(uri, useInternalNodes = TRUE, encoding = "UTF-8")
root_node <- xmlRoot(xml_doc)
xml_data <- xmlToDataFrame(nodes = getNodeSet(root_node, '//item'))
xml_data <- xml_data[order(xml_data$stdDay), ] # make ascending date

dat_gg <- xml_data %>% filter(gubunEn == "Gyeonggi-do") %>%
  select(createDt, localOccCnt)
dat <- dat_gg
names(dat) <- c("date", "daily_confirmed")
dat$date <- as.Date(dat$date)
dat$daily_confirmed <- as.numeric(dat$daily_confirmed) # orignally character
dat <- dat[!is.na(dat$daily_confirmed),]

ncat <- 19 # 19 categories for regions: 17 regions, imported, and total
days <- as.numeric(end_dt) - as.numeric(start_dt) + 1
 
if (nrow(xml_data) == (ncat * days)) {
  ## original data with full variables
  data_full <- readRDS("outputs/data_full.rds")
  xml_data <- xml_data[order(xml_data$stdDay), ] # make ascending date
  if (as.Date(tail(xml_data$createDt, 1)) > as.Date(tail(data_full$createDt, 1))) {
    data_full <- rbind(data_full, xml_data)
    saveRDS(data_full, "outputs/data_full.rds")
  }
}

```

## API COVID-19 data extraction by sex and age 
```{r}
library(XML)
library(RCurl)
library(dplyr)
# Sys.setlocale("LC_ALL", "Korean")
# options(encoding = "UTF-8")
## data portal
service_url <- "http://openapi.data.go.kr/openapi/service/rest/Covid19/getCovid19GenAgeCaseInfJson"
rows <- 4 #number of rows
## page
pg <- 1
# service key (register at https://www.data.go.kr/data/15043376/openapi.do)
# web site also provides a api request tool to check if the service key works
# decoded key works for the web site but in R encoded key (with the percent sign works)
service_key <- "KNu%2Fyp3%2FKm2MWttRvbZXNE%2Bb%2FEH44cfIYDvMgPFoSKUuKZIxqQoGu0gnAtwslGjupx%2BE6vp0bwf%2FSRPcLfXSYQ%3D%3D"

start_dt <- gsub("-", "", as.character(Sys.Date()))
end_dt <- start_dt

start_dt <- "20210101"
end_dt <- "20210806"

uri <-  paste0(service_url,
               paste0("?serviceKey=", service_key),
               paste0("&pageNo=", pg),
               paste0("&numOfRows=", rows),
               paste0("&startCreateDt=", start_dt),
               paste0("&endCreateDt=", end_dt))

xml_doc <- xmlTreeParse(uri, useInternalNodes = TRUE, encoding = "UTF-8")
root_node <- xmlRoot(xml_doc)
xml_data <- xmlToDataFrame(nodes = getNodeSet(root_node, '//item'))

# saveRDS(xml_data, "outputs/data_age_sex_20210101_20210806.rds")

# xml_data <- xml_data[order(xml_data$stdDay), ] # make ascending date

# ncat <- 19 # 19 categories for regions: 17 regions, imported, and total
# days <- as.numeric(end_dt) - as.numeric(start_dt) + 1
#  
# if (nrow(xml_data) == (ncat * days)) {
#   ## original data with full variables
#   data_full <- readRDS("outputs/data_full.rds")
#   xml_data <- xml_data[order(xml_data$stdDay), ] # make ascending date
#   if (as.Date(tail(xml_data$createDt, 1)) > as.Date(tail(data_full$createDt, 1))) {
#     data_full <- rbind(data_full, xml_data)
#     saveRDS(data_full, "outputs/data_full.rds")
#   }
# }

```

## API COVID-19 data extraction by testing, etc
```{r}
library(XML)
library(RCurl)
library(dplyr)
# Sys.setlocale("LC_ALL", "Korean")
# options(encoding = "UTF-8")
## data portal
service_url <- "http://openapi.data.go.kr/openapi/service/rest/Covid19/getCovid19InfStateJson"
rows <- 4 #number of rows
## page
pg <- 1
# service key (register at https://www.data.go.kr/data/15043376/openapi.do)
# web site also provides a api request tool to check if the service key works
# decoded key works for the web site but in R encoded key (with the percent sign works)
service_key <- "KNu%2Fyp3%2FKm2MWttRvbZXNE%2Bb%2FEH44cfIYDvMgPFoSKUuKZIxqQoGu0gnAtwslGjupx%2BE6vp0bwf%2FSRPcLfXSYQ%3D%3D"

start_dt <- "20200101"
end_dt <- "20201231"

uri <-  paste0(service_url,
               paste0("?serviceKey=", service_key),
               paste0("&pageNo=", pg),
               paste0("&numOfRows=", rows),
               paste0("&startCreateDt=", start_dt),
               paste0("&endCreateDt=", end_dt))

xml_doc <- xmlTreeParse(uri, useInternalNodes = TRUE, encoding = "UTF-8")
root_node <- xmlRoot(xml_doc)
xml_data <- xmlToDataFrame(nodes = getNodeSet(root_node, '//item'))

# xml_data <- xml_data[order(as.Date(xml_data$stateDt, format= "%Y%m%d")), ] 
# calcuate the daily new testing 
daily_test_completed <- accExamCompCnt[i] - accExamCompCnt[i-1]
diff_test_ongoing <- examCnt[i] - examCnt[i-1]
daily_testing[i] <- diff_test_ongoing + daily_test_completed 
# }
plot(diff(as.numeric(d$accExamCompCnt)), type="l")
```

```{r}
# d0 <- readRDS("outputs/data_full_20200601_20201231.rds")
d1 <- readRDS("outputs/data_full.rds")
dd <- rbind(d0, d1) 
dd %>%
  group_by(gubunEn) %>%
  summarize(n = n(), 
            sumIR = sum(as.numeric(qurRate)), 
            meanIR = mean(as.numeric(qurRate)))
```

